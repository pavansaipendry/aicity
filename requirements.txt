# ── LLMs ──────────────────────────────────────────────────────────────────────
anthropic==0.83.0
openai==2.21.0
# Ollama runs locally — no package needed, we use openai client pointed at
# http://localhost:11434/v1  (install Ollama from https://ollama.com)

# ── Web / Dashboard ────────────────────────────────────────────────────────────
fastapi==0.115.6
uvicorn==0.34.0
requests==2.32.5

# ── Memory & Storage ──────────────────────────────────────────────────────────
qdrant-client==1.17.0
redis==7.2.0
psycopg2-binary==2.9.11

# ── Utilities ─────────────────────────────────────────────────────────────────
python-dotenv==1.2.1
pydantic==2.12.5
loguru==0.7.3
rich==14.3.3

# ── Testing ───────────────────────────────────────────────────────────────────
pytest==8.3.4